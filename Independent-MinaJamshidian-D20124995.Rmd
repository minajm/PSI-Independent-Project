---
title: "Probability And Statistical Inference Math 9102(TU059)"
author: "Mina Jamshidian"
output: html_notebook
Student Number: D20124995
R version: 4.0.2 
---


Section 1 - Research Question(s)

1. Research Question

This analysis is about predicting whether a client with different  individual and social characteristics will subscribe to term deposit or not based on last contact duration?

This analysis would help us to find which factors could be considered to be perfect for prediction of determining a subscription situation.  
Furthermore this is a project that concerns whether clients' education, their age,  last contact duration with two contact types can be influenced on subscription of term deposit by clients.

2. Hypothesis

Hypothesis 1:
H0: There will be no significant predictor for client subscription of term deposit by client age and last call duration.
H1: There will be a significant predictor for client subscription of term deposit by their age and their last call duration.

Hypothesis 2:
H0: There will be no significant predictor for client subscription of term deposit by client age, client education and last call duration.
H1: There will be a significant predictor for client subscription of term deposit by their age, client education and their last call duration.



Section 2 - Dataset


# Loading Library
```{r, warning=FALSE}
# load lmSupport package for extra functions for linear model
library('lmSupport')

# load stargazer package for pretty print regression output
library('stargazer')

# load dplyr package to use functions for perform data manipulation
library(dplyr)

# load car package to use functions for regression
  library('car')

# load AutoModel package to use functions for modelling
# library(AutoModel)

# load rCompanion package to use Summary and Analysis functions
library('rcompanion')

# load pastecs package to use functions for generating descriptive statistics
library('pastecs')

# load semTools package to calculate skewness and kurtosis
library('lavaan')
# install.packages('semTools')
#library('semTools')

# load pander package to create table
library('pander')

# load pander package to use descriptive functions
library('psych')

# load ggplot2 package for plotting detailed graphs
library('ggplot2')

# load varhandle library to use unfactor function
library('varhandle')

# load effsize library to calculate eta-squared effect size
library('effsize')

# load Hmisc package for high level graphics
library('Hmisc')

# load stringr package to use functions for string operations
library('stringr')

# load lmtest package for funtion to compare models
library('lmtest')
library(caret)
library(AppliedPredictiveModeling)
library(janitor)
library(e1071)
library(sampler)

library(gmodels)
library(dplyr)
library(readr)
library(ROSE)
library(tidyr)
library(gplots)
library(lsr)
library(stargazer)
library(car)


```


# Importing Data
```{r, warning=FALSE}
# Cleaning Work space
rm(list = ls()) 
setwd("~/Desktop/TU Dublin/SEM 1/Prob. and Statistical Inference/Assignment/CA2/CA2-SI-3")

# importing the  bank marketing data csv file
bank = read.csv("bank-additional-full.csv",sep = ";")

```

# Treating Dataset and variables
```{r, warning=FALSE}
#searching for unknowns throughout the datset
colSums(bank == "unknown")

#converting the target variable to 0,1
# bank = bank %>% mutate(y_new= ifelse(y== "no",0,1))
bank= bank%>% mutate(age_label= if_else(age > 60,"senior-citizen",if_else(age>45,"mid-old",if_else(age>30,"Mid-age",if_else(age>15,"Young","Children")))))

#cleaning the unknown values for 4 variables based on their correlation with the target variable
CrossTable(bank$job,bank$y)
CrossTable(bank$marital,bank$y)
CrossTable(bank$education,bank$y)
CrossTable(bank$housing,bank$y)

bank = bank %>% filter( job!= "unknown")
bank = bank %>% filter( marital!= "unknown")
bank$education[bank$education=="unknown"]="university.degree"
bank = bank %>% filter( housing!= "unknown")
#removing column default & duration
bank = bank[-c(5)]
#Checking the unknown values again
colSums(bank == "unknown")

#Filter the dataset by campaign of less than 10
bank= bank%>%filter(campaign<10)


```

Variables of interest:
The variables of interest used in this research are shown below:

```{r, warning=FALSE}
# Create table

panderOptions('table.split.table',Inf)
data_variables<-"
Concept                           |  Variable Name | Statistical Type  | Possible Values
last contact duration, in seconds |  duration      |   Numerical       | Range 0 to 4918
client age                        |  age_label     | Categorical       | 1.age>60(senior-citizen) 2.age>45(mid-old) 3.age>30(Mid-age) 4. age>15(Young) 5.age<15(Children)
client subscribed a term deposit? |   y            | Categorical       | yes and no
contact communication type        |  contact       | Categorical       | cellular, telephone
client education                  |  education     | Categorical       | basic.4y to university.degree



"
df<-read.delim(textConnection(data_variables),header = FALSE,sep = '|',strip.white = TRUE,stringsAsFactors = FALSE)
names(df)<-unname(as.list(df[1,]))
df<-df[-1,]
row.names(df)<-NULL
pander(df,style='rmarkdown')

```


# Representativeness
```{r, warning=FALSE}

#balanced data by the  target variable
bank %>% count(y)
#https://www.rdocumentation.org/packages/ROSE/versions/0.0-3/topics/ovun.sample
# sbank=ovun.sample(y_new ~ ., data = bank, method = "over",N = 68602)$data
# sbank %>% count(y_new)

# Source: Sampling Design & Analysis, S. Lohr, 2000, equation 2.17
size <- rsampcalc(nrow(bank), e=5, ci=95,p=0.5, over=0.1)
sbank2<-ssamp(bank, size, y,over=0.1)
sbank2 %>% count(y)

# boo %>% count(y)
# 
# size <- rsampcalc(nrow(boo), e=5, ci=95,p=0.5, over=0.1)
# b2<-ssamp(boo, size, y,over=0.1)
# b2 %>% count(y)

```


## Statistical measurement 

Each of the variables of interest would be inspected. The numeric variables of interest, that representing the last contact duration with customer, in seconds. it would be inspected for normality by checking standardised scores for skewness and kurtosis and considering the percentage of standardised scores for the variables fell outside of expected boundaries and creating histograms and QQ plots. Decisions on skewness and kurtosis came from the advice of (George & Mallory, 2011) that categorizes a distribution as normal if the relevant standardised scores for skewness and kurtosis fall in the range +/- 2 and the advice of (Field, Miles & Field, 2012) which categorizes a distribution as normal if 95% of the standardised scores for the variable fall within the bounds of +/-3.29 for a dataset larger than 80 cases. Summary statistics of various nominal variables were also identified for analysis.

# Duration
Inspecting the Duration variable and its Normality by code:
```{r, warning=FALSE}
# Descriptive statistics
# getting summary statistics for duration variable
duration<- sbank2$duration
duration_d<-describe(duration,omit = TRUE, IQR = TRUE)
duration_s<-list(pastecs::stat.desc(duration, basic = FALSE))

skew         <- semTools::skew(duration)
kurt         <- semTools::kurtosis(duration)
stdskew      <- skew[1] / skew[2]
stdkurt      <- kurt[1] / kurt[2]
zscore       <- abs(scale(duration))
gt196        <- FSA::perc(as.numeric(zscore), 1.96, "gt")
gt329        <- FSA::perc(as.numeric(zscore), 3.29, "gt")

duration_s$skew <- skew
duration_s$kurt <- kurt
duration_s$std.skew <- stdskew
duration_s$std.kurt <- stdkurt
duration_s$gt.196 <- gt196
duration_s$gt.329 <- gt329
duration_s

# Distribution of Age variable with visualization 
ggplot(sbank2,aes(x=duration))+labs(x='duration', y='Density')+
  geom_histogram(binwidth = 30,colour='black',aes(y=..density..,fill=..count..))+
  scale_fill_gradient("Count",low="#132B43", high="#56B1F7")+
  stat_function(fun = dnorm,color="red",args = list(mean=mean(duration,na.rm = TRUE),sd=sd(duration,na.rm = TRUE)))+
  ggtitle('Distribution of Duration')+
  theme(plot.title = element_text(size=10))

# Create QQ Plot
qqnorm(duration, main = "QQplot of Duration")
qqline(duration,col=2) # show line on the plot


```

# Report of Normality Analysis

The Duration is represented by a numeric variable in the dataset. Inspection of the standardised scores for skewness and kurtosis reveal that the kurtosis score (*kurtosis* = 44.5, *SE* = .227) and the skewness score (*skewness* = 24.95, *SE* = .113) is out of that range which is the range of range of -2 and 2 . This implies that kurtosis and skewness is not normal. For further inspection using plots such as histogram and normality plot (figure 8 and figure 8), we found that the distribution is  positively skewed and not normalized. there are various values deviating from the normality line. On inspection of the count of outliers, there was found 2.1% standardised scores were outside the acceptable range of [-3.29, +3.29] that shows none of the values is outside the 95% Confidence Interval. In total, based on all the tests, it can be said that the data for duration variable will not be treated as a normal within this analysis. (*Median*=`r median(sbank2$duration,na.rm = TRUE)`, *IQR*=`r IQR(sbank2$duration,na.rm = TRUE)`,*M* = `r mean(sbank2$duration, na.rm=TRUE)`, *SD* = `r sd(sbank2$duration, na.rm=TRUE)`,  *N* = `r length(sbank2$duration)-sum(is.na(sbank2$duration))`).


# Transforming duration

After inspecting the duration variable,it was found that it was treated as non normal. In this analysis, the Log transformation was performed to this non normal data to convert it into the normal data before doing the linear parametric tests. This transformation approach was chosen because the Parametric test transformed normal data is considered more powerful compared to non parametric test on untransformed non normal data. So, the transformed duration variable would be used for result analysis and manipulation. 

Transforming the duration variable and Checking Normality by code:
```{r, warning=FALSE}
#Using the Log function for transforming duration
tduration<- log(sbank2$duration+10)

#adding the duration transformation to dataset table as new column by the name tduration 
sbank2 <- sbank2 %>% mutate(tduration)

tduration_d<-describe(tduration,omit = TRUE, IQR = TRUE)
tduration_s<-list(pastecs::stat.desc(tduration, basic = FALSE))

skew         <- semTools::skew(tduration)
kurt         <- semTools::kurtosis(tduration)
stdskew      <- skew[1] / skew[2]
stdkurt      <- kurt[1] / kurt[2]
zscore       <- abs(scale(tduration))
gt196        <- FSA::perc(as.numeric(zscore), 1.96, "gt")
gt329        <- FSA::perc(as.numeric(zscore), 3.29, "gt")

tduration_s$skew <- skew
tduration_s$kurt <- kurt
tduration_s$std.skew <- stdskew
tduration_s$std.kurt <- stdkurt
tduration_s$gt.196 <- gt196
tduration_s$gt.329 <- gt329
tduration_s

# Distribution of transformed duration(tduration) variable with visualization After Transformation
ggplot(sbank2,aes(x=tduration))+labs(x='Tranformed Duration', y='Density')+
  geom_histogram(binwidth = 0.5,colour='black',aes(y=..density..,fill=..count..))+
  scale_fill_gradient("Count",low="#132B43", high="#56B1F7")+
  stat_function(fun = dnorm,color="red",args = list(mean=mean(tduration,na.rm = TRUE),sd=sd(tduration,na.rm = TRUE)))+
  ggtitle('Distribution of Tranformed Duration')+
  theme(plot.title = element_text(size=10))

# Create QQ Plot
qqnorm(tduration, main = "QQplot of Tranformed Duration")
qqline(tduration,col=2) # show line on the plot

```

#### Report of Normality Analysis of Transformed Total HADS Anxiety data

Transformed duration variable is represented by a numeric variable which was calculated by doing Log function on the duration variable in the dataset. Inspecting the standardized scores for skewness (*skewness* = 1.23, *SE* = .113) and kurtosis (*kurtosis* = 1.16, *SE* = .227) shows that both of the skewness and the kurtosis value fall within the standardized score range of -2 and 2 which was implied that both skewness and kurtosis are normal. For further inspecting by using plots such as histogram and normality plot (figure 12 and figure 13), it was found that the distribution is normal. On inspection of the count of outliers, we found the 0% standardised scores were outside the acceptable range of [-3.29, +3.29]. which shows that none of the values is in outside of the 95% Confidence Interval. In total, it was found base all the test that was done the data for transformed duration variable has a normal distribution by this analysis (*M* = `r mean(tduration, na.rm=TRUE)`, *SD* = `r sd(tduration, na.rm=TRUE)`, *N* = `r length(tduration)-sum(is.na(tduration))`).


### Has the client subscribed to a term deposit?

Has the client subscribed a term deposit(y) is a nominal variable in the bank marketing dataset. The sample dataset contains data from 53 clients who subscribed 'Yes' and 403 clients who did not subscribe 'No'. The variable is representative of a sample which the clients  will subscribe to the term deposit.

#### Inspecting the variable by code:
```{r, warning=FALSE}
y<-table(sbank2$y)
y

# report basic summary statistics by a grouping variable
describeBy(tduration,sbank2$y)

#remove NA from if there is exist
dy<-data.frame(sbank2$y,tduration)
dy<-na.omit(dy)
names(dy)<-c("y","duration")

# Create box plot for the variable
medhelp_graph<-ggplot(dy,aes(y,duration))
medhelp_graph+stat_summary(fun.y = mean,geom = "bar",fill="#56B1F7",colour="black",na.rm = TRUE)+stat_summary(fun.data = mean_cl_normal,geom = "pointrange",na.rm = TRUE)+labs(x="Client subscribtion of term deposit",y="Last call duration",title="Mean call duration by Client subscribtion of term deposit")

```

### Age of client

Age of client is a categorical variable in the bank marketing dataset. The sample dataset has data from 9 clients in the senior-citizen group(age>60), 265 clients in the Mid-age group(age >45), 117 clients in the mid-old group(age>30), 71 clients in the young group(age>15). The variable is representative of a sample which is a client from a Portuguese banking institution.

#### Inspecting the variable by code:
```{r, warning=FALSE}
age_label<-table(sbank2$age_label)
age_label

# report basic summary statistics by a grouping variable
describeBy(tduration,sbank2$age_label)

#remove NA from if there is exist
dage<-data.frame(sbank2$age_label,tduration)
dage<-na.omit(dage)
names(dage)<-c("age_label","duration")

# Create box plot for the variable
medhelp_graph<-ggplot(dage,aes(age_label,duration))
medhelp_graph+stat_summary(fun.y = mean,geom = "bar",fill="#56B1F7",colour="black",na.rm = TRUE)+stat_summary(fun.data = mean_cl_normal,geom = "pointrange",na.rm = TRUE)+labs(x="Clients Age",y="Last call duration",title="Mean Last call duration by Clients age")

```

### Clients Education 

Client Education is a categorical variable in the bank marketing dataset. The sample dataset has data from 42 clients in basic.4y group education, 30 clients in the basic.6y education group, 81 clients in the basic.9y education group, 110 clients in the high.school education group, 58  clients in the professional.course education group, 141 clients in the university.degree education group. The variable is representative of a sample which is a client from a Portuguese banking institution.

#### Inspecting the variable by code:
```{r, warning=FALSE}

education<-table(sbank2$education)
education
sbank2$education[sbank2$education=="illiterate"]="basic.4y"

# report basic summary statistics by a grouping variable
describeBy(tduration,sbank2$education)

#remove NA from if there is exist
dedu<-data.frame(sbank2$education,tduration)
dedu<-na.omit(dedu)
names(dedu)<-c("education","duration")

# Create box plot for the variable
medhelp_graph<-ggplot(dedu,aes(education,duration))
medhelp_graph+stat_summary(fun.y = mean,geom = "bar",fill="#56B1F7",colour="black",na.rm = TRUE)+stat_summary(fun.data = mean_cl_normal,geom = "pointrange",na.rm = TRUE)+labs(x="Clients Education",y="Last call duration",title="Mean Last call duration by Clients Education")

```
### Contact Type 

Contact type is a categorical variable in the bank marketing dataset. The sample dataset has data from 297 clients by  cellular contact type, 165 clients by telephone contact type. The variable is representative of a sample which is a client from a Portuguese banking institution.

#### Inspecting the variable by code:
```{r, warning=FALSE}
contact<-table(sbank2$contact)
contact

# report basic summary statistics by a grouping variable
describeBy(tduration,sbank2$contact)

#remove NA from if there is exist
dcon<-data.frame(sbank2$contact,tduration)
dcon<-na.omit(dcon)
names(dcon)<-c("contact","duration")

# Create box plot for the variable
medhelp_graph<-ggplot(dcon,aes(contact,duration))
medhelp_graph+stat_summary(fun.y = mean,geom = "bar",fill="#56B1F7",colour="black",na.rm = TRUE)+stat_summary(fun.data = mean_cl_normal,geom = "pointrange",na.rm = TRUE)+labs(x="Contact Type",y="Last call duration",title="Mean Last call duration by Contact Type")
```


Section 3 - Results 

An alpha level of .05 was adopted for the Pearson Correlation Test and Cohen's rules on effect size (coefficient which is r) were adopted. For correlation, according to Cohen, the effect size is low if the r value varies around .1, medium if r varies around .3, and high if r varies more than .5 (Field, Miles & Field, 2012).A p-value lower than the level of significance of .05 indicates that the null hypothesis is clear evidence to reject it. The effect size is low if the value of eta-squared varies around .01, medium if eta-squared varies around .06, and high if eta-squared varies more than .14, as per Cohen, for difference (Field, Miles & Field, 2012).

### 4.1 Hypothesis 1

H0: There will be no significant predictor for client subscription of term deposit by client age and their last call duration.
H1: There will be a significant predictor for client subscription of term deposit by their age and their last call duration.

# Evaluate Variables
#### Check the difference in the last call duration for clients by different age groups.

```{r, warning=FALSE}
# Descriptive statistics by clients age group
durage<-na.omit(data.frame(sbank2$tduration,sbank2$age_label))
names(durage)<-c('tduration','age_label')

# Descriptive statistics by client age groups
describeBy(durage$tduration,durage$age_label)
mean_durage<-round(tapply(durage$tduration,durage$age_label,FUN =mean),digits = 2)
mean_durage

# The plot shows how mean values of last call duration changes with different client age groups and the number of people belonging to each group as well.
plotmeans(durage$tduration~durage$age_label,digits = 2,
          ccol = 'red',mean.labels = TRUE,xlab = 'Clients age group',ylab = 'Last call duration',
          main='Plot of Last call duration Mean by Clients age group')
#From the graph, we can understand that the mean value of last call duration differs for different groups.
#Last call duration with 'young' group having the lowest mean and Group 'senior-citizen' having the highest mean. 


#the boxplot analysis for further hypothesis testing was performed.
# Create boxplot
boxplot(durage$tduration~durage$age_label,
        main='Plot of Last call duration Score by Clients age group (dot is mean)',
        xlab = 'Clients age group',ylab = 'Last call duration',col=rainbow(6))
points(mean_durage,col='black',pch=18)
# As it was obvious in boxplots,  it was inferred that each client in different age groups has a different amount of variation in last call duration and there is a lot of overlap among values for different groups. But this information is not enough to provide evidence to simply affirm or reject null hypothesis as it does not give information whether the differences are statistically significant. To determine statistical significance, we need to assess the confidence intervals for the differences of means. We further investigate if the difference in mean values, considering there is a lot of overlap of last call duration for different clients groups, is because of variation within groups or variation among the groups. The ANOVA Test would be done. just because of variation within groups or variation among the groups. This is done using ANOVA Test.

# Bartlett test of homogeneity of variances
bartlett.test(durage$tduration,durage$age_label) 
# As it was aboviused in Figure 23 the p-value = .71 > .05 so the null hypothesis of the test is accepted and should be said that the variance of different groups can be assumed to be equal.

#Doing the assumption of homoscedasticity for Anova test for last call duration and clients in different age groups.
aov_durage<-aov(durage$tduration~durage$age_label)
summary(aov_durage)
# Since the value of F-statistic=2.05 > 1 (significant) and p-value=0.105 > 0.05, this shows that the variation among the groups and the variation within groups is high, so the mean values for different groups are not significantly different. Therefore, we could not reject the null hypothesis of the test which means the values for different groups are equal. In total, it was concluded that for the confidence interval the null hypothesis can not be rejected that there is no significant difference in last call duration for clients in different age groups.

etaSquared(aov_durage)
```

#### Report of Difference Analysis

A Bartlett's test was done and the equality of variance for Last call duration for all clients in different age group was indicated *K-squared* = 1.35, *P* = 0.7. 
A one-way between-groups analysis of variance was conducted to last call duration for clients in different age groups. clients were divided into four groups according to their age (Group 1 : senior-sitizen; Group 2 : Mid-age; Group 3 : mid-old; Group 4 : young). 
There was no statistically significant difference level in last call duration mean  for different clients age (*F(3, 262)* = 2.05, *p* = .105). 
The effect size, calculated using eta squared was .01. 
The test results indicate there is evidence to support accepting the null hypothesis that there is no difference in last call duration for clients in different age groups.



### Checking the difference in last duration call leads clients to subscribed a term deposit.

```{r, warning=FALSE, fig.width=10, fig.align='center'}

# Descriptive statistics 
contact<-as.factor(sbank2$y)

#Conduct Levene's test for homogeneity of variance in library car
ltest<-car::leveneTest(tduration ~ y, data=sbank2)
#Pr(F) is the probability
ltest

#Conduct the t-test from package stats
#You can use the var.equal = TRUE option to specify equal variances and a pooled variance estimate
stats::t.test(tduration~y,var.equal=TRUE,data=sbank2)
#Effect Size

effsize::cohen.d(tduration,y, alpha = 0.05, na.rm=TRUE)
# effet size=-19.23 large difference
```
#### Report of Difference Analysis

A Levene's test was conducted and indicated equality of variance for Last call duration for clients who subscribed the term deposit (*F-value* = 3.02, *P* = .08). A t-test analysis of variance was conducted to explore last call duration for clients who subscribed term deposit. Participants were divided into  groups according to which clients will subscribe to the term deposit(Group 1 : Yes, Group 2 : No). There was a statistically significant difference in last call duration mean scores for clients who subscribed to a term deposit.The p-value for two sample tests is very small which means it is significant and can reject the null hypothesis. The effect size, calculated using Cohen's d was -19.23 which implies there is a strong standardised mean difference for both groups. The test results indicate there is evidence to reject null alternative hypothesis which is no difference in Last call duration for clients who subscribed term deposit.


#### Build the linear regression models
### Baseline Model last call duration predicted that clients in different age groups  will subscribe to term deposit.

```{r}
#dummycode
df<-data.frame(sbank2)
which(names(df)=='age_label')
which(names(df)=='y')
which(names(df)=='education')
df<-df[,c(1,21,5)]
df$tduration<-tduration
df<-na.omit(df)
df
df$age_label=recode(df$age_label,"senior-citizen"="1","Mid-age"='2',"mid-old"='3',"Young"='4')
df$education=recode(df$education,'basic.4y'='1','basic.6y'='2','basic.9y'='3','high.school'='4','professional.course'='5','university.degree'='6')
df$y=recode(df$y,'yes'='1','no'='2')
df

model1=lm(df$tduration~df$y+df$age_label)
anova(model1)
summary(model1)

stargazer(model1, type="text") #Tidy output of all the required stats
plot(model1)
#Check assumptions
# List of   residuals
resid(model1)
#A density plot of the residuals
plot(density(resid(model1)))
# leverage plots
leveragePlots(model1) 
#Cooks distance
cooks.distance(model1)
#Plot Cooks distance
plot(cooks.distance(model1), ylab="Cook's statistic")
# none of the values is greater than 1 so no influential values
```
#### Report of Linear Modelling Analysis

A multiple linear regression analysis was conducted to determine if call duration,clients age lead the customer to subscribed the term deposit. A significant regression equation was found (*F(6,255)*=7.289, *p*=.003), with an Multiple R-squared=.1464.

Examination of the histogram, normal P-P plot of standardised residuals and the scatterplot of the dependent variable, last call duration, and standardised residuals showed that no outliers existed and the residuals followed normal distribution. Also, examination of the standardised residuals showed that none of the values was outside the standard range (95% within limits of -3.29 to +3.29) as the minimum and maximum values are -.74 and .70 respectively further affirming that there were no outliers. Also, none of the  Cook's distance were found to be more than 1, hence there are no influential values.

Examination for multicollinearity showed that the tolerance and variance influence factor measures were within acceptable levels (tolerance >0.4, VIF <2.5 ) as outlined in Tarling (2008). The scatterplot of standardised residuals showed that the data met the assumptions of homogeneity of variance and linearity. The data also meets the assumption of non-zero variances of the predictors.

Since all the assumptions for the model have been proven true and 14.64% of the variance in last call duration is explained by the considered predictors. On checking the significance levels for each of the main terms (in this case the coefficients associated with the constant, qualslp4, qualslp5 and qualslp6), we found that there is evidence that each of these terms are adding something to the model (they are statistically significant as p<.05). Hence, these statistical values provide enough evidence to reject that null hypothesis that there will be no significant prediction of last call duration by Medication to help you sleep and Clients age.


### 4.2 Hypothesis 2

H0: There will be no significant prediction of last call duration by Medication to help you sleep, Clients age and Rate of Stress over Last Month.

HA: There will be significant prediction of last call duration by Medication to help you sleep, Clients age and and Rate of Stress over Last Month.

#### Establish evidence for variables  
#### Check difference in last call duration for respondents of different Rate of Stress over Last Month.

```{r, warning=FALSE, fig.width=10, fig.align='center'}
# Descriptive statistics by Rate of Stress over Last Month
duredu<-na.omit(data.frame(tduration,sbank2$education))
names(duredu)<-c('tduration','education')
# Descriptive statistics by education
describeBy(duredu$tduration,duredu$education)
# check mean for each education group
mean_duredu<-round(tapply(duredu$tduration,duredu$education,FUN =mean),digits = 2)
mean_duredu
# The plot shows how last call duration Score means changes with different stressmo groups as well as the number of people belonging to each group 
plotmeans(duredu$tduration~duredu$education,digits = 2,
          ccol = 'red',mean.labels = TRUE,xlab = 'Rate of Stress Over Last Month',ylab = 'last call duration',main='Figure 12: Plot of last call duration Mean by Rate of Stress Over Last Month')
# From graph, we can infer that the Mean value of Total Depression Score differs for groups having different # rate of Stress over last month with group 'not at all' having the lowest mean and groups 8 and 9 having the # highest mean. We perform boxplot analysis for further hypothesis testing.
# Create boxplot
boxplot(duredu$tduration~duredu$education,
        main='Figure 13: Plot of last call duration by Rate of Stress over Last Month (mean is by black dot)',xlab = 'Rate of Stress Over Last Month',ylab = 'last call duration',col=rainbow(11))
points(mean_duredu,col='black',pch=18)
# Based on boxplots, it can infered that each education group has a different amount of variation in last call duration and there is a lot of overlap among values for different groups. But this information is not enough to provide evidence to simply affirm or reject null hypothesis as it does not give information whether the differences are statistically significant. To determine statistical significance, we need to assess the confidence intervals for the differences of means. We further investigate if the difference in mean values, considering there is a lot of overlap of last call duration for different groups, is because of variation within groups or variation among the groups. This is done using ANOVA Test.
# Checking the assumption of homoscedasticity for Anova Test
# Bartlett test of homogeneity of variances
# check if group 7.5 factor has atleast 2 observations
count=0
for(i in 1:length(duredu$education)){
  if(duredu$education[i]==7.5){
    count=count+1
  }
}
count
# remove the group 1 and 7.5 factor for Bartlett Test as it has less than 2 observations
duredu_new<-data.frame(duredu)
duredu_new<-droplevels.data.frame(duredu_new,exclude = 1)
duredu_new<-droplevels.data.frame(duredu_new,exclude = 7.5)
bartlett.test(duredu$tduration,duredu_new$education)
# p-value= .91 > .05, 
# null hypothesis of the test is accepted i.e. the variance of different groups can be assumed to be equal.
# Perform ANOVA Test
aov_duredu<-aov(duredu$tduration~duredu_new$education)
summary(aov_duredu)
# Since the value of F-statistic= 11.73 > 1 and p-value= 0.002 < 0.05, this implies that the variation among the sample means is higher than the variation within groups, hence the mean values for different groups are significantly different. Thus, we can reject the null hypothesis of the test that mean of values for different groups are equal and thereby accept the alternate hypothesis.We can say with confidence that there is statistically significant difference in mean values of last call duration for respondents of different Rate of Stress Levels over Last Month.
# As ANOVA does not give information about which groups are different from the others, we conduct
# a Post Hoc Test called Tukey Pairwise Comparison to evaluate group pairwise means.
tuk_duredu<-TukeyHSD(aov_duredu)
tuk_duredu
# Since the p-value for the pair of groups: '6-not at all', '7-not at all', '8-not at all', '9-not at all', 'extremely stressed-not at all','4-2','6-2','7-2','8-2',9-2','extremely stressed-2','8-3','9-3','extremely stressed-3', '9-4','8-5','9-5','9-6','9-7' is less than 0.05, there is difference in the last call duration mean values for these stressmo groups.
plot(tuk_duredu)
title(sub = "Figure 14")
# Confidence intervals that do not contain zero in plot indicate a mean difference that is statistically significant. The plot shows there is statistical difference for the pair of education groups: '6-not at all', '7-not at all', '8-not at all', '9-not at all', 'extremely stressed-not at all','4-2','6-2','7-2','8-2',9-2','extremely stressed-2','8-3','9-3','extremely stressed-3', '9-4','8-5','9-5','9-6','9-7' as their confidence levels don't cross the zero value.
```

#### Report of Difference Analysis

A Bartlett's test was conducted and indicated equality of variance for Last call duration for all groups of various Clients age (*K-squared* = 4.07, *P* = .91). A one-way between-groups analysis of variance was conducted to explore last call duration for respondents having Clients age. Participants were divided into  groups according to their Clients age (Group 1 : Very Poor; Group 2 : Poor; Group 3 : Fair; Group 4 : Good; Group 5 : Very Good; Group 6 : Excellent). There was statistically significant difference level in last call duration mean scores for respondents of different Clients age (*F(10, 257)* = 11.73, *p* = .002). Post-hoc comparisons using the Tukey HSD test indicated that the mean score for Clients age Group: '2' (*M* = 2.4, *SD* = .24) was statistically different to that of Group-'not at all' (*M* = 2.05, *SD* = .29); Group '3' (*M* = 2.25, *SD* = .26) was statistically different to that of Group-'not at all'(*M* = 2.05, *SD* = .29), Group '4' (*M* = 2.34, *SD* = .21) was statistically different to that of Group-'not at all' (*M* = 2.05, *SD* = .29), Group '5' (*M* = 2.31, *SD* = .25) was statistically different to that of Group-'not at all' (*M* = 2.05, *SD* = .29), Group '3' (*M* = 2.25, *SD* = .26) was statistically different to that of Group-'2' (*M* = 2.4, *SD* = .24), Group '5' (*M* = 2.31, *SD* = .25) was statistically different to that of Group-'2' (*M* = 2.4, *SD* = .24), Group '4' (*M* = 2.34, *SD* = .21) was statistically different to that of Group-'3' (*M* = 2.25, *SD* = .26), Group '5' (*M* = 2.31, *SD* = .25) was statistically different to that of Group-'3' (*M* = 2.25, *SD* = .26), Group '6' (*M* = 2.4, *SD* = .24) was statistically different to that of Group-'3' (*M* = 2.25, *SD* = .26), Group '5' (*M* = 2.31, *SD* = .25) was statistically different to that of Group-'4' (*M* = 2.34, *SD* = .21), Group '6' (*M* = 2.4, *SD* = .24) was statistically different to that of Group-'4'(*M* = 2.4, *SD* = .24), Group '7' (*M* = 2.43, *SD* = .29) was statistically different to that of Group-'4' (*M* = 2.43, *SD* = .29), Group '8' (*M* = 2.43, *SD* = .29) was statistically different to that of Group-'4' (*M* = 2.43, *SD* = .29), Group 'extremely stressed' (*M* = 2.4, *SD* = .24) was statistically different to that of Group-'4' (*M* = 2.4, *SD* = .24), Group '6' (*M* = 2.4, *SD* = .24) was statistically different to that of Group-'5' (*M* = 2.31, *SD* = .25), Group '7' (*M* = 2.43, *SD* = .29) was statistically different to that of Group-'5' (*M* = 2.31, *SD* = .25), Group 'extremely stressed' (*M* = 2.4, *SD* = .24) was statistically different to that of Group-'5' (*M* = 2.31, *SD* = .25), Group '7' (*M* = 2.31, *SD* = .25) was statistically different to that of Group-'6' (*M* = 2.4, *SD* = .24), Group '8' (*M* = 2.55, *SD* = .27) was statistically different to that of Group-'6' (*M* = 2.4, *SD* = .24), Group 'extremely stressed' (*M* = 2.4, *SD* = .24) was statistically different to that of Group-'6' (*M* = 2.4, *SD* = .24), Group '8' (*M* = 2.55, *SD* = .27) was statistically different to that of Group-'7' (*M* = 2.43, *SD* = .29), Group 'extremely stressed' (*M* = 2.4, *SD* = .24) was statistically different to that of Group-'7' (*M* = 2.55, *SD* = .27), Group '9' (*M* = 2.67, *SD* = .25) was statistically different to that of Group-'8' (*M* = 2.55, *SD* = .27) and Group 'extremely stressed' (*M* = 2.4, *SD* = .24) was statistically different to that of Group-'9' (*M* = 2.67, *SD* = .25).The effect size, calculated using eta squared was .31 which implies there is a moderate standardised mean difference for different groups. The test results indicate there is evidence to reject null hypothesis that there is no difference in Last call duration for respondents of different Clients age.

#### Build the linear regression models
### Model 2- tduration predicted by Total_Impact, Rate General Health and Rate of Stress over Last Month 

```{r}
model2<-lm(sbank2$tduration~sbank2$y_new+sbank2$age_label+sbank2$education)
anova(model2)
summary(model2)
stargazer(model2, type="text") #Tidy output of all the required stats
stargazer(model1, model2, type="text") #Quick model comparison
plot(model2)
#Check assumptions
# Create histogram 
# List of   residuals
resid(model2)
#A density plot of the residuals
plot(density(resid(model2))) 
# leverage plots
leveragePlots(model2) 
# Cooks distance
cooks.distance(model2)
#Plot Cooks distance
plot(cooks.distance(model2), ylab="Cook's statistic")
# none of the values is greater than 1 so no influential values
# Collinearity
vifmodel<-vif(model2)
vifmodel
# value < 2.5 not problem
1/(vifmodel)
# values > .4 not problem
```

#### Report of Linear Modelling Analysis

A multiple linear regression analysis was conducted to determine if Medication to help you sleep, Clients age and Rate of Stress over Last Month can predict last call duration in a person. A significant regression equation was found (*F(15,246)*=9.738, *p*=.002), with an Multiple R-squared=.3343.

Examination of the histogram, normal P-P plot of standardised residuals and the scatterplot of the dependent variable, last call duration, and standardised residuals showed that the no outliers existed and the residuals followed normal distribution. Also, examination of the standardised residuals showed that none of the values was outside the standard range (95% within limits of -3.29 to +3.29) as the minimum and maximum values are -.67 and .55 respectively further affirming that there were no outliers. Also, none of the  Cook's distance were found to be more than 1, hence there are no influential values.

Examination for multicollinearity showed that the tolerance and variance influence factor measures were within acceptable levels (tolerance >0.4, VIF <2.5 ) as outlined in Tarling (2008). The scatterplot of standardised residuals showed that the data met the assumptions of homogeneity of variance and linearity. The data also meets the assumption of non-zero variances of the predictors.

Since all the assumptions for the model have been proven true and 33.43% of the variance in last call duration is explained by the considered predictors. On checking the significance levels for each of the main terms (in this case the coefficients associated with the constant, qualslp4, qualslp5, qualslp6, education3, education4, stressmo5, stressmo6, stressmo7, stressmoextremelystressed), we found that there is evidence that each of these terms are adding something to the model (they are statistically significant as p<.05). Hence, these statistical values provide enough evidence to reject that null hypothesis that there will be no significant prediction of last call duration by Medication to help you sleep, Clients age and Rate of Stress over Last Month.



## Comparison of Models

# Compare Model 1 and Model 2
```{r compare model1, model2}
anova(model1,model2)
```

### Analysis of Model Comparison Results

As per the comparison, we can see that since the p-value obtained for second model (*p*=.003) is statistically significant (less than .05), hence addition of a new variable significantly improved the fit over model 1. Hence, we should reject model 1 and stick to model2.




## 5. Discussion

In this study, we aim to determine which factors can be considered to be the best predictors for determining person's state of Anxiety. This was been conducted using Multiple Linear Regression where we firstly tried to establish evidence that the various predictors chosen can be used for modelling. We investigated whether a person's Clients age, Stress Level over Last Month, Medication to help you sleep and General Health Rate make any difference to his state of Total Anxiety. We found that there were statistically significant differences in state of Total Anxiety among respondents of different Clients age, Stress Level over Last Month and General Health Rate. Furthermore, we built different models to determine which variables are the best for prediction.

First, the results of baseline model are analysed which determine whether Clients age and Medication to help you sleep can be used predictors for the output variable, Total Anxiety. Since the p-value for the model obtained is statistically significant (.003 <.05), it gives us evidence to suggest that the model is good to fit as it performs better than average score method for prediction. As per the analysis of squared-R value which is found to be .1464, we can say that 14.64% of the variance in Total Anxiety is explained by the considered predictors. On checking the significance levels for each of the main terms (in this case the coefficients associated with the constant, qualslp4, qualslp5 and qualslp6), we found that there is evidence that each of these terms are adding something to the model (they are statistically significant as p<.05). There were no outliers, residuals, leverage points and influential values found for the model. This model explained % of variance in Total Anxiety variable.

Second, the results of second model are analysed which determine whether Clients age, Medication to help you sleep and Rate of Stress over Last Month can be used as predictors for the output variable, Total Anxiety. Since the p-value for the model obtained is statistically significant (.002 <.05), it gives us evidence to suggest that the model is good to fit as it performs better than average score method for prediction. As per the analysis of squared-R value which is found to be .3343, we can say that 33.43% of the variance in Total Anxiety is explained by the considered predictors. On checking the significance levels for each of the main terms (in this case the coefficients associated with the constant, qualslp4, qualslp5, qualslp6, stressmo3, stressmo4, stressmo5, stressmo6, stressmo7, stressmoextremelystressed), we found that there is evidence that each of these terms are adding something to the model (they are statistically significant as p<.05). There were no outliers, residuals, leverage points and influential values found for the model. Due to the addition of a new predictor, Rate of Stress over Last Month, to the model has increased the amount of variance in Total Anxiety output variable being addressed by all the predictors, the coefficient associated with 'healthrate5' has become statistically insignificant. Overall, the second model can be considered better than the baseline model as it is statisticlly significant based on comparison results and addresses higher amount of variance in the output variable, Total Anxiety which implies it is better at making predictions.

Third, the results of third model are analysed which determine whether Clients age, Medication to help you sleep, Rate of Stress over Last Month and Rate General Health can be used as predictors for the output variable, Total Anxiety. Since the p-value for the model obtained is statistically significant (.002 <.05), it gives us evidence to suggest that the model is good to fit as it performs better than average score method for prediction. As per the analysis of squared-R value which is found to be .3732, we can say that 37.32% of the variance in Total Anxiety is explained by the considered predictors. On checking the significance levels for each of the main terms (in this case the coefficients associated with the constant, healthrate5, healthrate6, healthrate8, qualslp2, qualslp4, qualslp4, qualslp5, qualslp6, stressmo3, stressmo4, stressmo5, stressmo6, stressmo7 and stressmoextremelystressed), we found that there is evidence that each of these terms are adding something to the model (they are statistically significant as p<.05). There were no outliers, residuals, leverage points and influential values found for the model. Also, the coefficient associated with qualslp2 and qualslp4 have become statistically significant. Overall, although there is absence of any collinearity, the third model increases the amount of variance in the output variable, Total Anxiety which implies that third model is a better predictor compared to third model and comparison results also prove the same. This model also addresses higher amount of variance in the output variable, Total Anxiety which implies it is better at making predictions.

From this analysis, there is evidence to conclude that Model3 is the best model among others considered in this study as the predictors: Clients age, Medication to help you sleep, Rate of Stress over Last Month and Rate General Healthexplain 37.32% of the variance in Total Anxiety. Since this analysis has been carried out with the staff of a university in Melbourne, Australia, there is a scope of carrying further research to extrapolate the sample to represent generalized results for the entire population of Australia as strong results have been obtained.

## 6. References

Field, A., Miles, J., & Field, Z. (2012). *Discovering statistics using R. Sage publications.*

George, D. (2011). *SPSS for windows step by step: A simple study guide and reference, 17.0 update, 10/e. Pearson Education India.*















s

